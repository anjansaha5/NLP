{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex expression\n",
    "import re\n",
    "import nltk\n",
    "# using word corpus\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210687"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aal', 'aalii', 'aam', 'aardvark', 'aardwolf', 'aba', 'abac', 'abaca']\n"
     ]
    }
   ],
   "source": [
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many tasks involves finding a word which matches some pattern. For ex to find adverb, we can first find words which end with 'ly'. So for such patterns reg exp are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abactinally', 'abandonedly', 'abasedly', 'abashedly', 'abashlessly', 'abbreviately', 'abdominally', 'abhorrently', 'abidingly', 'abiogenetically']\n"
     ]
    }
   ],
   "source": [
    "# search function in regex\n",
    "#re.search(pattern, string)\n",
    "# $ is a meta charceter which looks to search at end\n",
    "print([w for w in wordlist if re.search('ly$', w)][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twibil', 'twibilled', 'twice', 'twicer', 'twicet', 'twichild', 'twick', 'twiddle', 'twiddler', 'twiddling']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('^twi', w)][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twilight']\n"
     ]
    }
   ],
   "source": [
    "# search for a bit complex pattern\n",
    "print([w for w in wordlist if re.search('^..il.g.t$', w)][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectedness', 'abjection', 'abjective', 'abjectly', 'abjectness', 'adjection', 'adjectional', 'adjectival', 'adjectivally', 'adjective']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('..j..t..', w )][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'ho', 'in', 'io']\n"
     ]
    }
   ],
   "source": [
    "print([w for w  in wordlist if re.search('^[ghi][mno]$', w)][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee', 'miiiiiinnnnnnnnnneeeeeeee', 'mine', 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']\n"
     ]
    }
   ],
   "source": [
    "# '+' indicates one or more of preceding charecter occurences\n",
    "# '*' means zero or more preceding charecters occurence\n",
    "# '-' is for range. For example 1-9 \n",
    "print([w for w in chat_words if re.search('^m+i+n+e+$', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '!!!!!!!!!!!', '!!!!....', '\"', '&', '(', '((((((((((((', '(((((((((((((((((((((((((', '))))))))', ')))))))))))))))))))))', '++', '--', '-s', '.. .', '...........', '.:', '10', '12%', '16', '1985']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in chat_words if re.search('^[^aeiouAIEOU]+$', w)][:200:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0085', '0.50', '1.01', '1.24', '1.5', '1.65', '1.916', '11.57', '118.6', '121.6', '13.65', '14.00', '14.99', '150.00', '16.9', '18.95', '2.1', '2.4', '2.7', '21.1']\n"
     ]
    }
   ],
   "source": [
    "# \\ operator just means the following charecter must be matched exactly.\n",
    "# note our interpretation of . operator was different\n",
    "\n",
    "print([w for w in corp if re.search('^[0-9]+\\.[0-9]+$', w)][:200:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.01', '1.14', '1.17', '1.18', '1.19', '1.20', '1.24', '1.25', '1.26', '1.28', '1.35', '1.39', '1.46', '1.49', '1.50', '1.55', '1.56', '1.61', '1.64', '1.65', '1.75', '1.76', '1.82', '1.85', '1.92']\n"
     ]
    }
   ],
   "source": [
    "# exercise : Get the numbers which start with only 1 and have only 2 decimals after.\n",
    "print([w for w in corp if re.search('^1\\.[0-9]{2}$', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n"
     ]
    }
   ],
   "source": [
    "#{4} indicates length of the word you are specifying\n",
    "print([w for w in corp if re.search('^[0-9]{4}$', w)][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting', 'savings-and-loan']\n"
     ]
    }
   ],
   "source": [
    "# {3,5} - allows 3 times or 5 times. {5,} allows five or more times occurences\n",
    "print([w for w in corp if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in corp if re.search('(ed|ing)$', w)][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download any html page (code from last class)\n",
    "   1. Identify all types of html tags (how does a html tag look like)\n",
    "   1. Count the number of articles occurrences.\n",
    "   1. How many words end with word 'ing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other applications of REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'i', 'e', 'e', 'o', 'u', 'e', 'e', 'e']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find all patterns inside a string and get the pattern rather than word\n",
    "word = 'GradvalleyDataScience-NLPCourse-Week2'\n",
    "re.findall(r'[aeiou]',word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(2, 3), match='a'>\n"
     ]
    }
   ],
   "source": [
    "word = 'GradvalleyDataScience-NLPCourse-Week2'\n",
    "print(re.search(r'[aeiou]',word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in words for vs in re.findall(r'[aieou]{2,}', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('ea', 476), ('oi', 65), ('ou', 329), ('io', 549), ('ee', 217), ('ie', 331), ('ui', 95), ('ua', 109), ('ai', 261), ('ue', 105), ('ia', 253), ('ei', 86), ('iai', 1), ('oo', 174), ('au', 106), ('eau', 10), ('oa', 59), ('oei', 1), ('oe', 15), ('eo', 39), ('uu', 1), ('eu', 18), ('iu', 14), ('aii', 1), ('aiia', 1), ('ae', 11), ('aa', 3), ('oui', 6), ('ieu', 3), ('ao', 6), ('iou', 27), ('uee', 4), ('eou', 5), ('aia', 1), ('uie', 3), ('iao', 1), ('eei', 2), ('uo', 8), ('uou', 5), ('eea', 1), ('ueui', 1), ('ioa', 1), ('ooi', 1)])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToolBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.corpus.toolbox.words('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kaa', 'kaa', 'kaa', 'kaakaaro', 'kaakaaviko', 'kaakaavo', 'kaakaoko', 'kaakasi', 'kaakau', 'kaakauko']\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "patterns = [cv for w in words for cv in re.findall(r'[ptksvr][aieou]', w)]\n",
    "cond_dict = nltk.ConditionalFreqDist(patterns)\n",
    "cond_dict.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
